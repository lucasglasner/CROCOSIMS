{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ZARR store\n",
    "\n",
    "In this notebook i will load raw data in xarray and then save on a zarr store for future work. (Its faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import cmaps\n",
    "import cmocean\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "import xesmf as xe\n",
    "import glob\n",
    "import regionmask\n",
    "import xgcm\n",
    "import dask\n",
    "import os\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_crocotime(DATA, YORIG, time_name='time'):\n",
    "    \"\"\"\n",
    "    Grab simulation time and transform to datetime objects based on given YORIG\n",
    "\n",
    "    Args:\n",
    "        DATA (XDataset, XDataArray): CROCO simulation data, with \"time\" coordinate \n",
    "        YORIG (str): Given reference date\n",
    "\n",
    "    Returns:\n",
    "        XDataset, XDataArray: Data with fixed time coordinate\n",
    "    \"\"\"\n",
    "    ORIG = pd.to_datetime(YORIG)\n",
    "    if time_name=='time':\n",
    "        new_time = pd.to_datetime([datetime.timedelta(seconds=t.item())+ORIG\n",
    "                                for t in DATA[time_name]])\n",
    "    else:\n",
    "        new_time = DATA[time_name]+ORIG\n",
    "        \n",
    "    DATA[time_name] = new_time\n",
    "    return DATA.sortby(time_name)\n",
    "\n",
    "def center_grid(data,variables):\n",
    "    \"\"\"\n",
    "    This function grabs a croco model outputs and moves the \n",
    "    arakawa-C edges variables (like u and v) to the center of the grid.\n",
    "\n",
    "    Args:\n",
    "        data (xarray): input dataset\n",
    "        variables (list): list of variables to transform\n",
    "\n",
    "    Returns:\n",
    "        xarray: dataset with variables in the center of the grid \n",
    "    \"\"\"\n",
    "    for v in variables:\n",
    "        if 'eta_v' in data[v].dims:\n",
    "            x = data[v].interp(eta_v=data.eta_rho.values)\n",
    "            x = x.rename({'eta_v':'eta_rho'})\n",
    "            data = data.drop(v)\n",
    "            data[v]=x\n",
    "        if 'eta_u' in data[v].dims:\n",
    "            x = data[v].interp(eta_u=data.eta_rho.values)\n",
    "            x = x.rename({'eta_u':'eta_rho'})\n",
    "            data = data.drop(v)\n",
    "            data[v]=x\n",
    "        if 'xi_u' in data[v].dims:\n",
    "            x = data[v].interp(xi_u=data.xi_rho.values)\n",
    "            x = x.rename({'xi_u':'xi_rho'})\n",
    "            data = data.drop(v)\n",
    "            data[v]=x\n",
    "        if 'xi_v' in data[v].dims:\n",
    "            x = data[v].interp(xi_v=data.xi_rho.values)\n",
    "            x = x.rename({'xi_v':'xi_rho'})\n",
    "            data = data.drop(v)\n",
    "            data[v]=x\n",
    "    return data\n",
    "\n",
    "def load_croco(paths, YORIG, time_name='time', variables=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Loading function for reading raw CROCO/ROMS outputs into\n",
    "    xarray objects. **kwargs are passed to xarray.open_dataset() function\n",
    "\n",
    "    Args:\n",
    "        paths (str, list): _description_\n",
    "        YORIG (str): _description_\n",
    "        variables (list, optional): _description_. Defaults to None.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If input path is not a string or list of strings\n",
    "\n",
    "    Returns:\n",
    "        xarray: loaded croco data\n",
    "    \"\"\"\n",
    "    if type(paths) == str:\n",
    "        if \"*\" in paths:\n",
    "            data = xr.open_mfdataset(paths,\n",
    "                                    concat_dim='time',\n",
    "                                    combine='nested',\n",
    "                                    **kwargs)\n",
    "            data = fix_crocotime(data, YORIG)\n",
    "        else:\n",
    "            data = xr.open_dataset(paths, **kwargs)\n",
    "            data = fix_crocotime(data, YORIG, time_name=time_name)\n",
    "    elif type(paths) == list:\n",
    "        data=[]\n",
    "        for p in paths:\n",
    "            d = xr.open_dataset(p, **kwargs)\n",
    "            d = fix_crocotime(d,YORIG, time_name=time_name)\n",
    "            data.append(d)\n",
    "        data = xr.concat(data,'time')\n",
    "    else:\n",
    "        raise ValueError('Path to croco output should only be a string or a list of strings.')\n",
    "    if variables==None:\n",
    "        data = center_grid(data, data.keys())\n",
    "    else:\n",
    "        data = center_grid(data, variables)[variables]\n",
    "    return data.sortby('time')\n",
    "\n",
    "def croco_sellonlatbox(data, lonmin, lonmax, latmin, latmax):\n",
    "    \"\"\"\n",
    "    This functions grabs a croco output and slice it to the\n",
    "    desired latlon bounds. \n",
    "    Only works for rho point centered variables (like temp, salt, zeta, etc)\n",
    "    The arakawa-C edges variables like zonal and meridional currents must first\n",
    "    be horizontally interpolated to the grid center.\n",
    "\n",
    "    Args:\n",
    "        data (xarray): loaded dataset (centered in rho points) as xarray object\n",
    "        lonmin (float): min longitude\n",
    "        lonmax (float): max longitude\n",
    "        latmin (float): min latitude\n",
    "        latmax (float): max latitude\n",
    "\n",
    "    Returns:\n",
    "        data: sliced data to the user defined latlon box \n",
    "    \"\"\"\n",
    "    data = data.sortby('eta_rho').sortby('xi_rho')\n",
    "    geoindex = ((data.lon_rho > lonmin) & (data.lon_rho<lonmax) & (data.lat_rho>latmin) & (data.lat_rho < latmax)).load()\n",
    "    geoindex = np.argwhere(geoindex.values)\n",
    "    xmin = min(geoindex[:,1])\n",
    "    xmax = max(geoindex[:,1])\n",
    "    ymin = min(geoindex[:,0])\n",
    "    ymax = max(geoindex[:,0])\n",
    "    data = data.sel(eta_rho=slice(ymin,ymax), xi_rho=slice(xmin,xmax))\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = xr.open_dataset('data/CROCO/OUTPUT/TESTSIM/3HERA5_GLORYS12V1/testsim_grd.nc').squeeze().load()\n",
    "grid = grid[['h','xi_rho','eta_rho','lon_rho','lat_rho','x_rho','y_rho','mask_rho']]\n",
    "grid['lon_rho'] = (grid.lon_rho+180)%360-180\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob.glob('data/CROCO/CROCO_FILES/testsim/24H/nomask/*blk*'))\n",
    "aforcing = [xr.open_dataset(p, chunks=dict(bulk_time=1))\n",
    "            for p in paths]\n",
    "aforcing = xr.concat(aforcing, 'bulk_time')\n",
    "aforcing = fix_crocotime(center_grid(aforcing, aforcing.variables), '1900-01-01 00:00:00', time_name='bulk_time')\n",
    "aforcing = aforcing.drop_duplicates('bulk_time').rename({'bulk_time':'time'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ceaza/lucas/miniconda3/envs/main/lib/python3.8/site-packages/xarray/core/dataset.py:2036: SerializationWarning: saving variable None with floating point data as an integer dtype without any _FillValue to use for NaNs\n",
      "  return to_zarr(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x7f121233ddd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aforcing.to_zarr('data/ZARR/testim_aforc_nomask', consolidated=True, mode='w')\n",
    "grid.to_zarr('data/ZARR/testim_aforc_nomask/', consolidated=True, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2006M1.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2006M10.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2006M11.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2006M12.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2006M2.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2006M3.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2006M4.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2006M5.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2006M6.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2006M7.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2006M8.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2006M9.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2007M1.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2007M10.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2007M11.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2007M12.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2007M2.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2007M3.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2007M4.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2007M5.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2007M6.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2007M7.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2007M8.nc\n",
      "data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/testsim_avg_Y2007M9.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ceaza/lucas/miniconda3/envs/main/lib/python3.8/site-packages/xarray/core/indexing.py:1234: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  value = value[(slice(None),) * axis + (subkey,)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x7ffa88931820>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "x = xr.open_dataset('data/CROCO/OUTPUT/TESTSIM/3HERA5_GLORYS12V1/testsim_avg_Y2006M1.nc')[['hc','Cs_r']]\n",
    "hc,Cs_r = x.hc.item(),x.Cs_r\n",
    "del x\n",
    "\n",
    "def rhopoints_depths(h, zeta, s_rho, Cs_r, hc, vtransform=2):\n",
    "    \"\"\" Compute depth of roms sigma levels.\n",
    "\n",
    "    Args:\n",
    "        h (_type_): _description_\n",
    "        zeta (_type_): _description_\n",
    "        s_rho (_type_): _description_\n",
    "        Cs_r (_type_): _description_\n",
    "        hc (_type_): _description_\n",
    "        vtransform (int, optional): _description_. Defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    if vtransform==1:\n",
    "        Z_rho = hc*(s_rho-Cs_r)+Cs_r*h\n",
    "        z_rho = Z_rho+zeta*(1+Z_rho/h)\n",
    "        return z_rho\n",
    "    else:\n",
    "        Z_rho = (hc*s_rho+Cs_r*h)/(hc+h)\n",
    "        z_rho = zeta+(zeta+h)*Z_rho\n",
    "        return z_rho\n",
    "    \n",
    "\n",
    "simulationpaths = sorted(glob.glob('data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/*avg*2006*'))+sorted(glob.glob('data/CROCO/OUTPUT/TESTSIM/BLK_NOMASK/*avg*2007*'))\n",
    "simulation = []\n",
    "for p in simulationpaths:\n",
    "    print(p)\n",
    "    x = load_croco(p, YORIG='1900-01-01 00:00:00',variables=['v','zeta','temp'], chunks=dict(time=1, eta_rho=-1, xi_rho=-1, s_rho=-1))\n",
    "    y = load_croco(p, YORIG='1900-01-01 00:00:00',variables=['temp'], chunks=dict(time=1, eta_rho=-1, xi_rho=-1, s_rho=-1)).isel(s_rho=-1).rename({'temp':'sst'})\n",
    "    simulation.append(xr.merge([x,y]))\n",
    "# simulation      = [xr.merge([load_croco(p, YORIG='1900-01-01 00:00:00',variables=['v','zeta'], chunks=None).load(),\n",
    "#                              load_croco(p, YORIG='1900-01-01 00:00:00', variables=['temp'], chunks=None).isel(s_rho=-1).load()])\n",
    "#                    for p in simulationpaths]\n",
    "simulation = xr.concat(simulation, 'time').where(grid.mask_rho==1).sortby('time')\n",
    "simulation['lon_rho'] = (simulation['lon_rho']+180)%360-180\n",
    "z_rho = rhopoints_depths(grid.h.expand_dims(dim={'s_rho':simulation.s_rho}), simulation.zeta, simulation.s_rho, Cs_r, hc)\n",
    "z_rho = z_rho.transpose('time', 's_rho', 'eta_rho', 'xi_rho')\n",
    "\n",
    "simulation.to_zarr('data/ZARR/testsim_BLKNOMASK', consolidated=True, mode='w')\n",
    "z_rho.to_dataset(name='z_rho').chunk({'time':1, 'eta_rho':-1, 'xi_rho':-1, 's_rho':-1}).to_zarr('data/ZARR/testsim_BLKNOMASK', consolidated=True, mode='a')\n",
    "\n",
    "# simulation.chunk({'time':1, 's_rho':50, 'eta_rho':292, 'xi_rho':324}).to_zarr('data/ZARR/testsim1', consolidated=True, mode='w')\n",
    "# z_rho.to_dataset(name='z_rho').chunk({'time':1, 's_rho':50, 'eta_rho':292, 'xi_rho':324}).to_zarr('data/ZARR/testsim1', consolidated=True, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbec8807e6558c264360eee38c7ea5d8701ec51362396b7d52ad24b952d04fb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
